 ğŸ§  UC AI Chatbot

An intelligent chatbot system built to assist users with University of Cincinnati-related queries, powered by Retrieval-Augmented Generation (RAG) using Google Gemini Pro (Flash 1.5), LangChain, and Chroma vector database.

---

## ğŸ“Œ Project Overview

The **UC AI Chatbot** is a full-stack AI application designed to provide intelligent, real-time answers about graduate admissions, academics, and university services at the University of Cincinnati. It uses state-of-the-art retrieval-based natural language processing with vector search and LLM-based reasoning.

---

## ğŸš€ Key Features

- ğŸ” **Semantic Search with Vector Embeddings**  
  Documents scraped from UC websites are converted to dense vector embeddings for semantic retrieval.

- ğŸ¤– **LLM-Powered Reasoning**  
  Integrated with Google Gemini Flash 1.5 using LangChainâ€™s `ChatGoogleGenerativeAI` for accurate, contextual responses.

- ğŸ§± **Modular Backend Architecture**  
  Built using **FastAPI** for high performance, with modular folders for crawling, embeddings, and model logic.

- ğŸ’¬ **Interactive Chat Interface**  
  Clean and responsive frontend with HTML + CSS that simulates a chat experience (submission and bot feedback).

- ğŸŒ **Portable & Cloud-Ready Deployment**  
  Easily deployable on Render, Railway, or Vercel with minimal configuration.

---

## ğŸ—ï¸ Architecture

uc-ai-chatbot/
â”‚
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ main.py # FastAPI app with web routes
â”‚ â”œâ”€â”€ templates/index.html # Frontend chat UI
â”‚ â”œâ”€â”€ static/style.css # Chatbot styling
â”‚
â”œâ”€â”€ crawler/
â”‚ â”œâ”€â”€ crawler.py # UC website scraper
â”‚ â””â”€â”€ data/pages/ # Scraped HTML content
â”‚
â”œâ”€â”€ embeddings/
â”‚ â””â”€â”€ embedder.py # Chroma vector DB creation
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ query_llm.py # LLM QA chain setup
â”‚
â”œâ”€â”€ .env # API keys and config
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ render.yaml # Render deployment configuration (optional)
â””â”€â”€ README.md # Youâ€™re here!
## âš™ï¸ Technologies Used

| Category       | Tools/Frameworks                          |
|----------------|-------------------------------------------|
| ğŸ§  LLM          | Google Gemini 1.5 Flash (via LangChain)   |
| ğŸ“¦ Embeddings  | HuggingFace `all-MiniLM-L6-v2`            |
| ğŸ” Vector DB    | Chroma                                    |
| ğŸš€ Web Framework | FastAPI                                   |
| ğŸ¨ Frontend     | HTML, CSS (static/chat UI)                |
| ğŸ§ª Others       | `python-multipart`, `uvicorn`, `dotenv`  |

---
2. Install Dependencies
pip install -r requirements.txt
3. Set Up .env
Create a .env file in the root directory:
env
GOOGLE_API_KEY=your_google_api_key
CHROMA_DB_DIR=embeddings/chroma_db
4. Run the Application
uvicorn app.main:app --reload
Access the chatbot at: http://localhost:8000

ğŸ’» Deployment (Optional)
If you're deploying on Render, include render.yaml.
If using Vercel or Railway, configure build and start scripts in your dashboard or via vercel.json.
Status & Limitations
âœ… Backend + LLM pipeline complete
âœ… Frontend chat UI working
âš ï¸ Deployment may exceed free-tier limits on Render or Railway due to LLM + embedding model size
ğŸ“š Skills Demonstrated
ğŸ”§ Backend API Development (FastAPI)
ğŸ¤– LLM Integration (Google Gemini Flash 1.5 via LangChain)
ğŸ“Š Semantic Search & Vector DB (Chroma)
ğŸ§  Prompt Engineering & RetrievalQA Chains
ğŸ’» Full-stack system design with modular folder structure
ğŸ› ï¸ Deployment Readiness (Render, Vercel, Railway)
